{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 파이썬 모듈 설치 - 모듈 설치가 전부 되어 있다면 실행하지 않기\n",
    "from IPython.display import clear_output\n",
    "! pip install tqdm\n",
    "! pip install sentence_transformers\n",
    "! pip install pandas\n",
    "clear_output()\n",
    "print(\"설치된 모듈 : tqdm, sentence_transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\seclab\\anaconda3\\envs\\Capstone\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SentenceBERT 모델 종류 선언\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_type = [\n",
    "    # 기본 SentenceBERT 모델 (0~1)\n",
    "    \"bert-large-nli-mean-tokens\",\n",
    "    \"bert-large-nli-stsb-mean-tokens\",\n",
    "    # 사전 훈련된 SentenceBERT 모델 (2~3)\n",
    "    \"distilbert-base-nli-stsb-mean-tokens\", # 가볍고 빠름\n",
    "    \"roberta-large-nli-stsb-mean-tokens\", # 무겁지만 성능이 뛰어남\n",
    "    # 다국어 SentenceBERT 모델 (4~5) - 한국어 포함\n",
    "    \"paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    \"distiluse-base-multilingual-cased\",\n",
    "    # 도메인 특화 SBERT 모델 (6~7)\n",
    "    \"all-mpnet-base-v2\", # 일반적인 문장 의미에 좋은 성능을 보여줌\n",
    "    \"msmarco-distilbert-base-v4\", # 검색 관련 좋은 성능을 보여줌\n",
    "    # 한국어 SBERT 모델 (8~9)\n",
    "    \"BM-K/KoSimCSE-roberta\", # 다양한 한국어 데이터로 학습된 모델\n",
    "    \"jhgan/ko-sbert-sts\", # 한국어 문장 유사도 (STS) 데이터로 학습한 모델\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 개수 : 1379\n",
      "bert-large-nli-mean-tokens :  0.3686,  69.2232s\n",
      "bert-large-nli-stsb-mean-tokens :  0.3241,  66.3417s\n",
      "distilbert-base-nli-stsb-mean-tokens :  0.3651,  13.2555s\n",
      "roberta-large-nli-stsb-mean-tokens :  0.3914,  73.2906s\n",
      "paraphrase-multilingual-MiniLM-L12-v2 :  0.7392,  9.0851s\n",
      "distiluse-base-multilingual-cased :  0.7421,  9.2493s\n",
      "all-mpnet-base-v2 :  0.3689,  23.3165s\n",
      "msmarco-distilbert-base-v4 :  0.3319,  13.6524s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name BM-K/KoSimCSE-roberta. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM-K/KoSimCSE-roberta :  0.8009,  10.7297s\n",
      "jhgan/ko-sbert-sts :  0.8078,  12.9897s\n"
     ]
    }
   ],
   "source": [
    "# 모델 성능 테스트\n",
    "from sentence_transformers import util\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time, os, torch\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# STS 데이터셋 불러오기\n",
    "# sts_type = \"STSB\"\n",
    "# sts_list = os.listdir(f\"./data/{sts_type}\")\n",
    "# sts_list = [f for f in sts_list if f[0] != '.']\n",
    "# if sts_list[0].endswith('.tsv'):\n",
    "#     sts_df = pd.read_csv(f\"./data/{sts_type}/\" + sts_list[0], sep=\"\\t\", on_bad_lines='skip')\n",
    "#     for sts_file in sts_list[1:]:\n",
    "#         sts_df = pd.concat([sts_df.copy(), pd.read_csv(f\"./data/{sts_type}/\" + sts_file, sep='\\t', on_bad_lines='skip')], ignore_index=True)\n",
    "# elif sts_list[0].endswith('.parquet'):\n",
    "#     sts_df = pd.read_parquet(f\"./data/{sts_type}/\" + sts_list[0], engine=\"pyarrow\")\n",
    "#     for sts_file in sts_list[1:]:\n",
    "#         sts_df = pd.concat([sts_df.copy(), pd.read_parquet(f\"./data/{sts_type}/\" + sts_file, engine=\"pyarrow\")], ignore_index=True)\n",
    "sts_df = pd.read_csv(f\"./data/KorSTS/sts-test.tsv\", sep=\"\\t\", on_bad_lines='skip')\n",
    "print(f\"데이터 개수 : {len(sts_df)}\")\n",
    "sentence1 = sts_df[\"sentence1\"].astype(str)\n",
    "sentence2 = sts_df[\"sentence2\"].astype(str)\n",
    "score = sts_df[\"score\"]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name in model_type[0:]:\n",
    "    start_time = time.time()\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embeddings1 = model.encode(sentence1, convert_to_tensor=True).to(device)\n",
    "    embeddings2 = model.encode(sentence2, convert_to_tensor=True).to(device)\n",
    "    cos_sim = torch.nn.functional.cosine_similarity(embeddings1, embeddings2).cpu().numpy()\n",
    "\n",
    "    norm_cos_sim = (cos_sim + 1) * 2.5 # -1~1 범위를 0~5 범위로 정규화\n",
    "    spearman_corr, _ = spearmanr(score, norm_cos_sim)\n",
    "\n",
    "    results[model_name] = [spearman_corr, time.time() - start_time]\n",
    "    torch.cuda.empty_cache()\n",
    "    del model, embeddings1, embeddings2, cos_sim, norm_cos_sim, spearman_corr, _\n",
    "    print(f\"{model_name} : {results[model_name][0] : .4f}, {results[model_name][1] : .4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-large-nli-mean-tokens :  0.8015,  54.7349s\n",
      "bert-large-nli-stsb-mean-tokens :  0.9501,  156.1642s\n",
      "distilbert-base-nli-stsb-mean-tokens :  0.9481,  32.3018s\n",
      "roberta-large-nli-stsb-mean-tokens :  0.9447,  179.9490s\n",
      "paraphrase-multilingual-MiniLM-L12-v2 :  0.8488,  25.7859s\n",
      "distiluse-base-multilingual-cased :  0.7979,  34.7029s\n",
      "all-mpnet-base-v2 :  0.8490,  61.0560s\n",
      "msmarco-distilbert-base-v4 :  0.7749,  32.2363s\n",
      "BM-K/KoSimCSE-roberta :  0.7139,  79.9904s\n",
      "jhgan/ko-sbert-sts :  0.7401,  81.9747s\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_type:\n",
    "    print(f\"{model_name} : {results[model_name][0] : .4f}, {results[model_name][1] : .4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 입력\n",
    "import os\n",
    "\n",
    "data_path = \"./data/kwiki\"\n",
    "data_name = \"kwiki_02\"\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "with open(f\"{data_path}/{data_name}.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data_a = f.read() # 원본 문서\n",
    "with open(f\"{data_path}/{data_name}_q.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data_b = f.read() # 질의 문서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Type : jhgan/ko-sbert-sts\n",
      "Q : 일반 상대성이론은 1915년에 발표된 알베르트 아인슈타인의 이론으로, 뉴턴의 만유인력 법칙을 수정하였어.\n",
      "S :  0.8384\n",
      "Q : 우주에 관한 해를 얻기 위해서는 공간의 밀도가 균일한 먼지로 가득 채워져 있다는 전제 하에 아인슈타인 방정식을 대입해 알아낼 수 있어.\n",
      "S :  0.6013\n",
      "Q : 천체물리학에서 블랙혹이라는 밀도가 매우 높은 새로운 종류의 천체를 일반 상대론을 통해 예측합니다.\n",
      "S :  0.5179\n"
     ]
    }
   ],
   "source": [
    "# 1. 문서 전체 임베딩 알고리즘\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(model_type[9])\n",
    "print(f\"Model Type : {model_type[9]}\")\n",
    "\n",
    "embedding_a = model.encode(data_a)\n",
    "questions = data_b.split('\\n')\n",
    "for question in questions:\n",
    "    embedding_b = model.encode(question)\n",
    "    print(f\"Q : {question}\")\n",
    "    print(f\"S : {util.cos_sim(embedding_a, embedding_b).item() : .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Type : jhgan/ko-sbert-sts\n",
      "Q : 관리자는 접속 기간 중 최소 80% 이상 보고서를 작성해야 합니다. 개인적인 이유로 결석이 필요할 경우, 반드시 사전에 본부장의 승인을 받아야 하며, 3일 이상 무단 결석 시 연수비 지원이 중단됩니다.\n",
      "A :  관리자는 반드시 보고서를 접속 기간의 80% 이상 작성해야 한다.\n",
      "S :  0.7545\n",
      "Q : 관리가 종료된 후 7일 이내에 성과 보고서, 출석 기록, 그리고 계좌 사본을 각각 1부씩 제출해야 합니다.\n",
      "A :  관리 종료 후 7일 이내 결과보고서, 출석부 및 계좌 사본 각 1부\n",
      " 제출\n",
      " 3.\n",
      "S :  0.9208\n",
      "Q : 관리자는 관리자 교육 과정을 필수적으로 이수해야 합니다.\n",
      "A :  관리자는 반드시 관리자 교육 이수해야 한다.\n",
      "S :  0.9182\n",
      "Q : * 관리자 유의 사항 * 접속 기간 중 보고서 80% 이상 작성 필요\n",
      "A :  관리자는 반드시 보고서를 접속 기간의 80% 이상 작성해야 한다.\n",
      "S :  0.8883\n"
     ]
    }
   ],
   "source": [
    "# 2. 문장 단위 임베딩 알고리즘\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import re\n",
    "\n",
    "model = SentenceTransformer(model_type[9])\n",
    "print(f\"Model Type : {model_type[9]}\")\n",
    "\n",
    "data_a = re.sub(r'\\s*formula_\\d+\\s*', '', data_a)\n",
    "data_a = re.sub(r'\\n+', '\\n', data_a).strip()\n",
    "\n",
    "sentences_a = data_a.split('.'); sentences_a = [s + '.' for  s in sentences_a]\n",
    "sentences_a = [s for s in sentences_a if len(s) >= 11]\n",
    "questions = data_b.split('\\n')\n",
    "\n",
    "for question in questions:\n",
    "    embedding_b = model.encode(question)\n",
    "    max_sim = -1; max_idx = -1\n",
    "    for idx in range(len(sentences_a)):\n",
    "        cur_sim = util.cos_sim(model.encode(sentences_a[idx]), embedding_b)\n",
    "        max_idx = idx if cur_sim > max_sim else max_idx\n",
    "        max_sim = cur_sim if cur_sim > max_sim else max_sim\n",
    "    print(f\"Q : {question}\")\n",
    "    print(f\"A : {sentences_a[max_idx]}\")\n",
    "    print(f\"S : {max_sim.item() : .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Type : jhgan/ko-sbert-sts\n",
      "Q : 일반 상대성이론은 1915년에 발표된 알베르트 아인슈타인의 이론으로, 뉴턴의 만유인력 법칙을 수정하였어.\n",
      "A : 은 1915년 발표된 알베르트 아인슈타인의 고전적 중력이론으로, 특수 상대론을 확장한 기하학적 중력 모형에 근거하여 뉴턴의 만유인력 법칙을 수정한 이론이다. 일반 상대론은 현대의 \n",
      "S :  0.9148\n",
      "Q : 우주에 관한 해를 얻기 위해서는 공간의 밀도가 균일한 먼지로 가득 채워져 있다는 전제 하에 아인슈타인 방정식을 대입해 알아낼 수 있어.\n",
      "A : 물리 우주론.공간이 밀도가 균일한 먼지로 가득 채워져 있다고 가정하여 아인슈타인 방정식에 대입하면 우주에 관한 해를 얻을 수 있으며, 우주와 관련된 여러 지표에 따라서 우주 공간의\n",
      "S :  0.9311\n",
      "Q : 천체물리학에서 블랙혹이라는 밀도가 매우 높은 새로운 종류의 천체를 일반 상대론을 통해 예측합니다.\n",
      "A :  천체물리학과 우주론의 기반이 된다. 천체물리학에서 일반 상대론은 중성자별, 블랙홀이라는 밀도가 매우 높아 극한의 중력 환경을 제공하는 새로운 종류의 천체를 예측한다. 이러한 천체\n",
      "S :  0.7799\n"
     ]
    }
   ],
   "source": [
    "# 3. 슬라이딩 윈도우 임베딩 알고리즘\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import re\n",
    "\n",
    "model = SentenceTransformer(model_type[9])\n",
    "print(f\"Model Type : {model_type[9]}\")\n",
    "\n",
    "data_a = re.sub(r'\\s*formula_\\d+\\s*', '', data_a)\n",
    "data_a = re.sub(r'\\n+', '', data_a).strip()\n",
    "\n",
    "sentences_a = []\n",
    "window_size = 100 # Window Size\n",
    "\n",
    "for i in range(0, len(data_a)-window_size):\n",
    "    sentences_a.append(data_a[i:i+window_size])\n",
    "questions = data_b.split('\\n')\n",
    "\n",
    "for question in questions:\n",
    "    embedding_b = model.encode(question)\n",
    "    max_sim = -1; max_idx = -1\n",
    "    embedding_a = []\n",
    "    for idx in range(len(sentences_a)):\n",
    "        embedding_a.append(model.encode(sentences_a[idx]))\n",
    "    for idx in range(len(sentences_a)):\n",
    "        cur_sim = util.cos_sim(embedding_a[idx], embedding_b)\n",
    "        max_idx = idx if cur_sim > max_sim else max_idx\n",
    "        max_sim = cur_sim if cur_sim > max_sim else max_sim\n",
    "    print(f\"Q : {question}\")\n",
    "    print(f\"A : {sentences_a[max_idx]}\")\n",
    "    print(f\"S : {max_sim.item() : .4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
